{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ApBMdVyJdAtk",
        "tPh5A2sGdH8M",
        "l9NFXw1_dRl5",
        "KAgHEwdpdUcq",
        "IJZeOiRPdcBM"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#installation"
      ],
      "metadata": {
        "id": "ApBMdVyJdAtk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio youtube_transcript_api sentence-transformers langchain-community langchain PyPDF2 nltk bs4 openpyxl faiss-cpu python-docx python-pptx"
      ],
      "metadata": {
        "id": "irNeLdh4LSi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing"
      ],
      "metadata": {
        "id": "RHnrkDZvdDq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import json\n",
        "import docx\n",
        "import pptx\n",
        "import re\n",
        "import nltk\n",
        "import time\n",
        "import PyPDF2\n",
        "import tempfile\n",
        "import openpyxl\n",
        "import requests\n",
        "import gradio as gr\n",
        "from bs4 import BeautifulSoup\n",
        "import xml.etree.ElementTree as ET\n",
        "from nltk.tokenize import word_tokenize\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "from langchain_community.llms import HuggingFaceEndpoint\n",
        "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
        "from langchain_community.chat_models.huggingface import ChatHuggingFace\n",
        "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
        "from youtube_transcript_api._errors import NoTranscriptFound, TranscriptsDisabled, VideoUnavailable\n",
        "nltk.download('punkt')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"your_hf_token\""
      ],
      "metadata": {
        "id": "Wt6VO1PrbxDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Processing"
      ],
      "metadata": {
        "id": "tPh5A2sGdH8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_csv(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8', errors='ignore', newline='') as csvfile:\n",
        "        csv_reader = csv.reader(csvfile)\n",
        "        csv_data = [row for row in csv_reader]\n",
        "    return ' '.join([' '.join(row) for row in csv_data])\n",
        "\n",
        "def read_text(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8', errors='ignore',  newline='') as f:\n",
        "        return f.read()\n",
        "\n",
        "def read_pdf(file_path):\n",
        "    text_data = []\n",
        "    with open(file_path, 'rb') as pdf_file:\n",
        "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "        for page in pdf_reader.pages:\n",
        "            text_data.append(page.extract_text())\n",
        "    return '\\n'.join(text_data)\n",
        "\n",
        "def read_docx(file_path):\n",
        "    doc = docx.Document(file_path)\n",
        "    return '\\n'.join([paragraph.text for paragraph in doc.paragraphs])\n",
        "\n",
        "def read_pptx(file_path):\n",
        "    ppt = pptx.Presentation(file_path)\n",
        "    text_data = ''\n",
        "    for slide in ppt.slides:\n",
        "        for shape in slide.shapes:\n",
        "            if hasattr(shape, \"text\"):\n",
        "                text_data += shape.text + '\\n'\n",
        "    return text_data\n",
        "\n",
        "def read_xlsx(file_path):\n",
        "    workbook = openpyxl.load_workbook(file_path)\n",
        "    sheet = workbook.active\n",
        "    text_data = ''\n",
        "    for row in sheet.iter_rows(values_only=True):\n",
        "        text_data += ' '.join([str(cell) for cell in row if cell is not None]) + '\\n'\n",
        "    return text_data\n",
        "\n",
        "def read_json(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        json_data = json.load(f)\n",
        "    return json.dumps(json_data)\n",
        "\n",
        "def read_html(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        html_content = f.read()\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "    return soup\n",
        "\n",
        "def read_xml(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    return ET.tostring(root, encoding='unicode')\n",
        "\n",
        "def process_youtube_video(url, languages=['en', 'ar']):\n",
        "    if 'youtube.com/watch' in url or 'youtu.be/' in url:\n",
        "        try:\n",
        "            if \"v=\" in url:\n",
        "                video_id = url.split(\"v=\")[1].split(\"&\")[0]\n",
        "            elif \"youtu.be/\" in url:\n",
        "                video_id = url.split(\"youtu.be/\")[1].split(\"?\")[0]\n",
        "            else:\n",
        "                return \"Invalid YouTube video URL. Please provide a valid YouTube video link.\"\n",
        "\n",
        "            response = requests.get(f\"http://img.youtube.com/vi/{video_id}/mqdefault.jpg\")\n",
        "            if response.status_code != 200:\n",
        "                return \"Video doesn't exist.\"\n",
        "\n",
        "            transcript_data = []\n",
        "            for lang in languages:\n",
        "                try:\n",
        "                    transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=[lang])\n",
        "                    transcript_data.append(' '.join([entry['text'] for entry in transcript]))\n",
        "                except (NoTranscriptFound, TranscriptsDisabled, VideoUnavailable):\n",
        "                    continue\n",
        "\n",
        "            return ' '.join(transcript_data) if transcript_data else \"Please choose a YouTube video with available English or Arabic transcripts.\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"An error occurred: {e}\"\n",
        "    else:\n",
        "        return \"Invalid YouTube URL. Please provide a valid YouTube link.\"\n",
        "\n",
        "def read_web_page(url):\n",
        "    result = requests.get(url)\n",
        "    if result.status_code == 200:\n",
        "        src = result.content\n",
        "        soup = BeautifulSoup(src, 'html.parser')\n",
        "        text_data = ''\n",
        "        for p in soup.find_all('p'):\n",
        "            text_data += p.get_text() + '\\n'\n",
        "        return text_data\n",
        "    else:\n",
        "        return \"Please provide a valid webpage link\"\n",
        "\n",
        "def read_data(file_path_or_url, languages=['en', 'ar']):\n",
        "    if file_path_or_url.endswith('.csv'):\n",
        "        return read_csv(file_path_or_url)\n",
        "    elif file_path_or_url.endswith('.txt'):\n",
        "        return read_text(file_path_or_url)\n",
        "    elif file_path_or_url.endswith('.pdf'):\n",
        "        return read_pdf(file_path_or_url)\n",
        "    elif file_path_or_url.endswith('.docx'):\n",
        "        return read_docx(file_path_or_url)\n",
        "    elif file_path_or_url.endswith('.pptx'):\n",
        "        return read_pptx(file_path_or_url)\n",
        "    elif file_path_or_url.endswith('.xlsx'):\n",
        "        return read_xlsx(file_path_or_url)\n",
        "    elif file_path_or_url.endswith('.json'):\n",
        "        return read_json(file_path_or_url)\n",
        "    elif file_path_or_url.endswith('.html'):\n",
        "        return read_html(file_path_or_url)\n",
        "    elif file_path_or_url.endswith('.xml'):\n",
        "        return read_xml(file_path_or_url)\n",
        "    elif 'youtube.com/watch' in file_path_or_url or 'youtu.be/' in file_path_or_url:\n",
        "        return process_youtube_video(file_path_or_url, languages)\n",
        "    elif file_path_or_url.startswith('http'):\n",
        "        return read_web_page(file_path_or_url)\n",
        "    else:\n",
        "        return \"Unsupported type or format.\"\n",
        "\n",
        "def normalize_text(text):\n",
        "    text = re.sub(\"\\*?\", \"\", text)\n",
        "    text = text.lower()\n",
        "    text = text.strip()\n",
        "    punctuation = '''!()[]{};:'\"\\<>/?$%^&*_`~='''\n",
        "    for punc in punctuation:\n",
        "        text = text.replace(punc, \"\")\n",
        "    text = re.sub(r'[A-Za-z0-9]*@[A-Za-z]*\\.?[A-Za-z0-9]*', \"\", text)\n",
        "    words = word_tokenize(text)\n",
        "    return ' '.join(words)"
      ],
      "metadata": {
        "id": "aIjhMourcNk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepairing the models"
      ],
      "metadata": {
        "id": "l9NFXw1_dRl5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=\"HuggingFaceH4/starchat2-15b-v0.1\",\n",
        "    task=\"text-generation\",\n",
        "    max_new_tokens=4096,\n",
        "    temperature=0.6,\n",
        "    top_p=0.9,\n",
        "    top_k=40,\n",
        "    repetition_penalty=1.2,\n",
        "    do_sample=True,\n",
        ")\n",
        "chat_model = ChatHuggingFace(llm=llm)\n",
        "\n",
        "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
        "embedding_llm = SentenceTransformerEmbeddings(model_name=model_name)\n",
        "db = FAISS.load_local(\"faiss_index\", embedding_llm, allow_dangerous_deserialization=True)\n",
        "\n",
        "def print_like_dislike(x: gr.LikeData):\n",
        "    print(x.index, x.value, x.liked)\n",
        "\n",
        "def user(user_message, history):\n",
        "  if not len(user_message):\n",
        "    raise gr.Error(\"Chat messages cannot be empty\")\n",
        "  return \"\", history + [[user_message, None]]\n",
        "\n",
        "def user2(user_message, history, link):\n",
        "    if not len(user_message) or not len(link):\n",
        "        raise gr.Error(\"Chat messages or links cannot be empty\")\n",
        "    combined_message = f\"{link}\\n{user_message}\"\n",
        "    return \"\", history + [[combined_message, None]], link\n",
        "\n",
        "def user3(user_message, history, file_path):\n",
        "    if not len(user_message) or not file_path:\n",
        "        raise gr.Error(\"Chat messages or flies cannot be empty\")\n",
        "    combined_message = f\"{file_path}\\n{user_message}\"\n",
        "    return \"\", history + [[combined_message, None]], file_path\n",
        "\n",
        "messages1 = [\n",
        "  SystemMessage(content=\"You are a helpful assistant.\"),\n",
        "  HumanMessage(content=\"Hi AI, how are you today?\"),\n",
        "AIMessage(content=\"I'm great thank you. How can I help you?\")]\n",
        "messages2 = messages1.copy()\n",
        "messages3 = messages1.copy()\n",
        "messages4 = messages1.copy()\n",
        "messages5 = messages1.copy()"
      ],
      "metadata": {
        "id": "qW5uVXGbcT5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing Modes of Chating"
      ],
      "metadata": {
        "id": "KAgHEwdpdUcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Chat_Message(history):\n",
        "    global messages1\n",
        "\n",
        "    message=HumanMessage(content=history[-1][0])\n",
        "    messages1.append(message)\n",
        "    response = chat_model.invoke(messages1)\n",
        "    messages1.append(AIMessage(content=response.content))\n",
        "\n",
        "    if len(messages1) >= 8:\n",
        "      messages1 = messages1[-8:]\n",
        "\n",
        "    history[-1][1] = \"\"\n",
        "    for character in response.content:\n",
        "        history[-1][1] += character\n",
        "        time.sleep(0.0025)\n",
        "        yield history\n",
        "\n",
        "def Web_Search(history):\n",
        "    global messages2\n",
        "\n",
        "    message=history[-1][0]\n",
        "\n",
        "    similar_docs = db.similarity_search(message, k=3)\n",
        "\n",
        "    if similar_docs:\n",
        "        source_knowledge = \"\\n\".join([x.page_content for x in similar_docs])\n",
        "    else:\n",
        "        source_knowledge = \"\"\n",
        "\n",
        "    augmented_prompt = f\"\"\"\n",
        "    You are an AI designed to help understand and extract information from provided Search Content. Based on the user's Query, you may need to summarize the text, answer specific questions, or provide guidance.\n",
        "    Query: {message}\n",
        "    Search Content:\n",
        "    {source_knowledge}\n",
        "\n",
        "    #If the query is not related to specific Search Content, engage in general conversation or provide relevant information from other sources.\n",
        "    \"\"\"\n",
        "\n",
        "    msg=HumanMessage(content=augmented_prompt)\n",
        "    messages2.append(msg)\n",
        "\n",
        "    if len(messages2) >= 8:\n",
        "        messages2 = messages2[-8:]\n",
        "\n",
        "    response = chat_model.invoke(messages2)\n",
        "    messages2.append(AIMessage(content=response.content))\n",
        "\n",
        "    history[-1][1] = \"\"\n",
        "    for character in response.content:\n",
        "        history[-1][1] += character\n",
        "        time.sleep(0.0025)\n",
        "        yield history\n",
        "\n",
        "def Chart_Generator(history):\n",
        "    global messages3\n",
        "\n",
        "    message = history[-1][0]\n",
        "    if '#chart' in message:\n",
        "        message = message.split('#chart', 1)[1].strip()\n",
        "        chart_url = f\"https://quickchart.io/natural/{message}\"\n",
        "        response = requests.get(chart_url)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            image_html = f'<img src=\"{chart_url}\" alt=\"Generated Chart\" style=\"display: block; margin: auto; max-width: 100%; max-height: 100%;\">'\n",
        "            message_with_description = f\"Describe and analyse the content of this chart: {chart_url}\"\n",
        "\n",
        "            prompt = HumanMessage(content=message_with_description)\n",
        "            messages3.append(prompt)\n",
        "\n",
        "            if len(messages3) >= 8:\n",
        "                messages3 = messages3[-8:]\n",
        "\n",
        "            response = chat_model.invoke(messages3)\n",
        "            messages3.append(AIMessage(content=response.content))\n",
        "\n",
        "            combined_content = f'{image_html}<br>{response.content}'\n",
        "        else:\n",
        "            response_text = \"Can't generate this image. Please provide valid chart details.\"\n",
        "            combined_content = response_text\n",
        "    else:\n",
        "        prompt = HumanMessage(content=message)\n",
        "        messages3.append(prompt)\n",
        "\n",
        "        if len(messages3) >= 8:\n",
        "            messages3 = messages3[-8:]\n",
        "\n",
        "        response = chat_model.invoke(messages3)\n",
        "        messages3.append(AIMessage(content=response.content))\n",
        "\n",
        "        combined_content=response.content\n",
        "\n",
        "    history[-1][1] = \"\"\n",
        "    for character in combined_content:\n",
        "        history[-1][1] += character\n",
        "        time.sleep(0.0025)\n",
        "        yield history\n",
        "\n",
        "def Link_Scratch(history):\n",
        "    global messages4\n",
        "\n",
        "    combined_message = history[-1][0]\n",
        "\n",
        "    link = \"\"\n",
        "    user_message = \"\"\n",
        "    if \"\\n\" in combined_message:\n",
        "        link, user_message = combined_message.split(\"\\n\", 1)\n",
        "        link = link.strip()\n",
        "        user_message = user_message.strip()\n",
        "\n",
        "    result = read_data(link)\n",
        "\n",
        "    if result in [\"Unsupported type or format.\", \"Please provide a valid webpage link\",\n",
        "                  \"Invalid YouTube URL. Please provide a valid YouTube link.\",\n",
        "                  \"Please choose a YouTube video with available English or Arabic transcripts.\",\n",
        "                  \"Invalid YouTube video URL. Please provide a valid YouTube video link.\"]:\n",
        "        response_message = result\n",
        "    else:\n",
        "        content_data = normalize_text(result)\n",
        "        if not content_data:\n",
        "            response_message = \"The provided link is empty or does not contain any meaningful words.\"\n",
        "        else:\n",
        "            augmented_prompt = f\"\"\"\n",
        "            You are an AI designed to help understand and extract information from provided Link Content. Based on the user's Query, you may need to summarize the text, answer specific questions, or provide guidance.\n",
        "            Query: {user_message}\n",
        "            Link Content:\n",
        "            {content_data}\n",
        "\n",
        "            #If the query is not related to specific Link Content, engage in general conversation or provide relevant information from other sources.\n",
        "            \"\"\"\n",
        "            message = HumanMessage(content=augmented_prompt)\n",
        "            messages4.append(message)\n",
        "\n",
        "            if len(messages4) >= 2:\n",
        "                messages4 = messages4[-2:]\n",
        "\n",
        "            response = chat_model.invoke(messages4)\n",
        "            messages4.append(AIMessage(content=response.content))\n",
        "\n",
        "            response_message = response.content\n",
        "\n",
        "    history[-1][1] = \"\"\n",
        "    for character in response_message:\n",
        "        history[-1][1] += character\n",
        "        time.sleep(0.0025)\n",
        "        yield history\n",
        "\n",
        "def insert_line_breaks(text, every=8):\n",
        "    return '\\n'.join(text[i:i+every] for i in range(0, len(text), every))\n",
        "\n",
        "def display_file_name(file):\n",
        "    supported_extensions = ['.csv', '.txt', '.pdf', '.docx', '.pptx', '.xlsx', '.json', '.html', '.xml']\n",
        "    file_extension = os.path.splitext(file.name)[1]\n",
        "    if file_extension.lower() in supported_extensions:\n",
        "      file_name = os.path.basename(file.name)\n",
        "      file_name_with_breaks = insert_line_breaks(file_name)\n",
        "      icon_url = \"https://img.icons8.com/ios-filled/50/0000FF/file.png\"\n",
        "      return f\"<div style='display: flex; align-items: center;'><img src='{icon_url}' alt='file-icon' style='width: 20px; height: 20px; margin-right: 5px;'><b style='color:blue;'>{file_name_with_breaks}</b></div>\"\n",
        "    else:\n",
        "      raise gr.Error(\"( Supported File Types Only : PDF , CSV , TXT , DOCX , PPTX , XLSX , JSON , HTML , XML )\")\n",
        "\n",
        "def File_Interact(history,filepath):\n",
        "    global messages5\n",
        "\n",
        "    combined_message = history[-1][0]\n",
        "\n",
        "    link = \"\"\n",
        "    user_message = \"\"\n",
        "    if \"\\n\" in combined_message:\n",
        "      link, user_message = combined_message.split(\"\\n\", 1)\n",
        "      user_message = user_message.strip()\n",
        "\n",
        "    result = read_data(filepath)\n",
        "\n",
        "    if result == \"Unsupported type or format.\":\n",
        "        response_message = result\n",
        "    else:\n",
        "        content_data = normalize_text(result)\n",
        "        if not content_data:\n",
        "            response_message = \"The file is empty or does not contain any meaningful words.\"\n",
        "        else:\n",
        "            augmented_prompt = f\"\"\"\n",
        "            You are an AI designed to help understand and extract information from provided File Content. Based on the user's Query, you may need to summarize the text, answer specific questions, or provide guidance.\n",
        "            Query: {user_message}\n",
        "            File Content:\n",
        "            {content_data}\n",
        "\n",
        "            #If the query is not related to specific File Content, engage in general conversation or provide relevant information from other sources.\n",
        "            \"\"\"\n",
        "            message = HumanMessage(content=augmented_prompt)\n",
        "            messages5.append(message)\n",
        "\n",
        "            if len(messages5) >= 1:\n",
        "                messages5 = messages5[-1:]\n",
        "\n",
        "            response = chat_model.invoke(messages5)\n",
        "            messages5.append(AIMessage(content=response.content))\n",
        "\n",
        "            response_message = response.content\n",
        "\n",
        "    history[-1][1] = \"\"\n",
        "    for character in response_message:\n",
        "        history[-1][1] += character\n",
        "        time.sleep(0.0025)\n",
        "        yield history"
      ],
      "metadata": {
        "id": "LXwLYqQncaBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Construct Gradio Interface"
      ],
      "metadata": {
        "id": "IJZeOiRPdcBM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MW_Hc99YLQlX"
      },
      "outputs": [],
      "source": [
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "  with gr.Row():\n",
        "    gr.Markdown(\"\"\"<span style='font-weight: bold; color: blue; font-size: large;'>Choose Your Mode</span>\"\"\")\n",
        "    gr.Markdown(\"\"\"<div style='margin-left: -120px;'><span style='font-weight: bold; color: blue; font-size: xx-large;'>IT ASSISTANT</span></div>\"\"\")\n",
        "\n",
        "  with gr.Tab(\"Chat-Message\"):\n",
        "    chatbot = gr.Chatbot(\n",
        "          [],\n",
        "          elem_id=\"chatbot\",\n",
        "          bubble_full_width=False,\n",
        "          height=500,\n",
        "          placeholder=\"<span style='font-weight: bold; color: blue; font-size: x-large;'>Feel Free To Ask Me Anything Or Start A Conversation On Any Topic...</span>\"\n",
        "      )\n",
        "    with gr.Row():\n",
        "      msg = gr.Textbox(show_label=False, placeholder=\"Type a message...\", scale=10, container=False)\n",
        "      submit = gr.Button(\"➡️Send\", scale=1)\n",
        "\n",
        "    clear = gr.ClearButton([msg, chatbot])\n",
        "\n",
        "    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=True).then(Chat_Message, chatbot, chatbot)\n",
        "    submit.click(user, [msg, chatbot], [msg, chatbot], queue=True).then(Chat_Message, chatbot, chatbot)\n",
        "    chatbot.like(print_like_dislike, None, None)\n",
        "\n",
        "  with gr.Tab(\"Web-Search\"):\n",
        "    chatbot = gr.Chatbot(\n",
        "        [],\n",
        "        elem_id=\"chatbot\",\n",
        "        bubble_full_width=False,\n",
        "        height=500,\n",
        "        placeholder=\"<span style='font-weight: bold; color: blue; font-size: x-large;'>Demand What You Seek, And I'll Search The Web For The Most Relevant Information...</span>\"\n",
        "    )\n",
        "    with gr.Row():\n",
        "      msg = gr.Textbox(show_label=False, placeholder=\"Type a message...\", scale=10, container=False)\n",
        "      submit = gr.Button(\"➡️Send\", scale=1)\n",
        "\n",
        "    clear = gr.ClearButton([msg, chatbot])\n",
        "\n",
        "    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=True).then(Web_Search, chatbot, chatbot)\n",
        "    submit.click(user, [msg, chatbot], [msg, chatbot], queue=True).then(Web_Search, chatbot, chatbot)\n",
        "    chatbot.like(print_like_dislike, None, None)\n",
        "\n",
        "  with gr.Tab(\"Chart-Generator\"):\n",
        "    chatbot = gr.Chatbot(\n",
        "        [],\n",
        "        elem_id=\"chatbot\",\n",
        "        bubble_full_width=False,\n",
        "        height=500,\n",
        "        placeholder=\"<span style='font-weight: bold; color: blue; font-size: x-large;'>Request Any Chart Or Graph By Giving The Data Or A Description, And I'll Create It...</span>\"\n",
        "    )\n",
        "\n",
        "    with gr.Row():\n",
        "      msg = gr.Textbox(show_label=False, placeholder=\"To generate a chart: type #chart [your chart description ]. To discuss the chart: type your message directly...\", scale=10, container=False)\n",
        "      submit = gr.Button(\"➡️Send\", scale=1)\n",
        "\n",
        "    clear = gr.ClearButton([msg, chatbot])\n",
        "\n",
        "    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=True).then(Chart_Generator, chatbot, chatbot)\n",
        "    submit.click(user, [msg, chatbot], [msg, chatbot], queue=True).then(Chart_Generator, chatbot, chatbot)\n",
        "    chatbot.like(print_like_dislike, None, None)\n",
        "\n",
        "  with gr.Tab(\"Link-Scratch\"):\n",
        "    chatbot = gr.Chatbot(\n",
        "        [],\n",
        "        elem_id=\"chatbot\",\n",
        "        bubble_full_width=False,\n",
        "        height=500,\n",
        "        placeholder=\"<span style='font-weight: bold; color: blue; font-size: x-large;'>Provide A Link Of Web page Or YouTube Video And Inquire About Its Details...</span>\"\n",
        "    )\n",
        "\n",
        "    with gr.Row():\n",
        "        msg1 = gr.Textbox(show_label=False, placeholder=\"Paste your link...\", scale=4, container=False)\n",
        "        msg2 = gr.Textbox(show_label=False, placeholder=\"Type a message...\", scale=7, container=False)\n",
        "        submit = gr.Button(\"➡️Send\", scale=1)\n",
        "\n",
        "    clear = gr.ClearButton([msg2, chatbot, msg1])\n",
        "\n",
        "    msg1.submit(user2, [msg2, chatbot, msg1], [msg2, chatbot, msg1], queue=True).then(Link_Scratch, chatbot, chatbot)\n",
        "    msg2.submit(user2, [msg2, chatbot, msg1], [msg2, chatbot, msg1], queue=True).then(Link_Scratch, chatbot, chatbot)\n",
        "    submit.click(user2, [msg2, chatbot, msg1], [msg2, chatbot, msg1], queue=True).then(Link_Scratch, chatbot, chatbot)\n",
        "    chatbot.like(print_like_dislike, None, None)\n",
        "\n",
        "  with gr.Tab(\"File-Interact\"):\n",
        "    chatbot = gr.Chatbot(\n",
        "        [],\n",
        "        elem_id=\"chatbot\",\n",
        "        bubble_full_width=False,\n",
        "        height=500,\n",
        "        placeholder=\"<span style='font-weight: bold; color: blue; font-size: x-large;'>Upload A File And Explore Questions Related To Its Content...</span><br>( Supported File Types Only : PDF , CSV , TXT , DOCX , PPTX , XLSX , JSON , HTML , XML )\"\n",
        "    )\n",
        "\n",
        "    with gr.Column():\n",
        "        with gr.Row():\n",
        "            filepath = gr.UploadButton(\"Upload a file\", file_count=\"single\", scale=1)\n",
        "            msg = gr.Textbox(show_label=False, placeholder=\"Type a message...\", scale=7, container=False)\n",
        "            submit = gr.Button(\"➡️Send\", scale=1)\n",
        "        with gr.Row():\n",
        "            file_output = gr.HTML(\"<div style='height: 20px; width: 30px;'></div>\")\n",
        "            clear = gr.ClearButton([msg, filepath, chatbot,file_output],scale=6)\n",
        "\n",
        "    filepath.upload(display_file_name, inputs=filepath, outputs=file_output)\n",
        "\n",
        "    msg.submit(user3, [msg, chatbot, file_output], [msg, chatbot, file_output], queue=True).then(File_Interact, [chatbot, filepath],chatbot)\n",
        "    submit.click(user3, [msg, chatbot, file_output], [msg, chatbot, file_output], queue=True).then(File_Interact, [chatbot, filepath],chatbot)\n",
        "    chatbot.like(print_like_dislike, None, None)\n",
        "\n",
        "demo.queue(max_size=10, default_concurrency_limit=4)\n",
        "demo.launch(max_file_size=\"5mb\", show_api=False, max_threads=50)"
      ]
    }
  ]
}